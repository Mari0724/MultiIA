from torchvision import transforms  # Para transformaciones de im√°genes (rotar, normalizar, etc.)
from torchvision.datasets import ImageFolder  # Para leer im√°genes organizadas en carpetas
from torch.utils.data import DataLoader, Subset  # DataLoader = hace batches, Subset = selecciona subconjunto
from pathlib import Path  # Manejo elegante de rutas de archivos/carpetas
from app.vision.utils.preprocess import preprocess_image  # Tu funci√≥n personalizada para procesar im√°genes
import torch  # Framework principal de deep learning


# üîπ Definimos una clase para personalizar la forma en que se leen las im√°genes
class CustomDataset(ImageFolder):
    def __init__(self, root, transform=None):
        # Llamamos al constructor de la clase padre (ImageFolder)
        # root = carpeta ra√≠z donde est√°n las im√°genes
        super().__init__(root, transform=transform)

    # Esta funci√≥n define c√≥mo obtener UN solo elemento (imagen + etiqueta) del dataset
    def __getitem__(self, index):
        # Obtenemos la ruta de la imagen y la etiqueta (0 o 1 en este caso)
        path, label = self.samples[index]
        
        # Procesamos la imagen con tu funci√≥n preprocess_image (convierte a tensor)
        tensor = preprocess_image(path, for_batch=False)
        
        # Devolvemos la imagen ya transformada y su etiqueta
        return tensor, label



# üîπ Funci√≥n para crear los DataLoaders (entrenamiento, validaci√≥n, test)
def get_loaders(batch_size=32, subset_debug=False):
    # Localizamos la carpeta base (subimos dos niveles desde este archivo)
    BASE_DIR = Path(__file__).resolve().parent.parent
    
    # Definimos la ruta donde est√°n los datos
    data_dir = BASE_DIR / "data" / "chest_xray"

    # Creamos datasets para cada partici√≥n de los datos
    train_dataset = CustomDataset(root=data_dir / "train")  # Im√°genes de entrenamiento
    val_dataset = CustomDataset(root=data_dir / "val")      # Im√°genes de validaci√≥n
    test_dataset = CustomDataset(root=data_dir / "test")    # Im√°genes de prueba final

    # üîπ Opci√≥n: usar solo un subconjunto peque√±o del dataset (√∫til para pruebas r√°pidas)
    if subset_debug:
        # Tomamos solo 200 im√°genes para entrenar
        train_dataset = Subset(train_dataset, list(range(200)))
        # Tomamos solo 50 im√°genes para validar
        val_dataset = Subset(val_dataset, list(range(50)))

    # Creamos DataLoaders que cargan los datos en lotes (batches)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)   # shuffle=True ‚Üí mezcla cada √©poca
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)      # validaci√≥n NO necesita mezcla
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)    # test tampoco

    # Retornamos los 3 cargadores listos para usar en entrenamiento
    return train_loader, val_loader, test_loader
